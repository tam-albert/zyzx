{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1476,"status":"ok","timestamp":1708265835572,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"LNGk4NrE6hYS","outputId":"665666bd-bf9f-45d7-adf4-1c82bde0947e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# import google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15780,"status":"ok","timestamp":1708265852980,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"AFdrfbJbFq52","outputId":"0defedd8-b76c-4d6b-cccd-774b00068b42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: accelerate==0.26.1 in /usr/local/lib/python3.10/dist-packages (0.26.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (6.0.1)\n","Requirement already satisfied: torch\u003e=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (0.20.3)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.26.1) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.10.0-\u003eaccelerate==0.26.1) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-\u003eaccelerate==0.26.1) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-\u003eaccelerate==0.26.1) (4.66.2)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.10.0-\u003eaccelerate==0.26.1) (2.1.5)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate==0.26.1) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate==0.26.1) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate==0.26.1) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub-\u003eaccelerate==0.26.1) (2024.2.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.10.0-\u003eaccelerate==0.26.1) (1.3.0)\n","Requirement already satisfied: datasets==2.16.1 in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.13.1)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (1.25.2)\n","Requirement already satisfied: pyarrow\u003e=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.6)\n","Requirement already satisfied: dill\u003c0.3.8,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (1.5.3)\n","Requirement already satisfied: requests\u003e=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2.31.0)\n","Requirement already satisfied: tqdm\u003e=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.70.15)\n","Requirement already satisfied: fsspec[http]\u003c=2023.10.0,\u003e=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (3.9.3)\n","Requirement already satisfied: huggingface-hub\u003e=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.16.1) (6.0.1)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.16.1) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.16.1) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.16.1) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.16.1) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.16.1) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets==2.16.1) (4.0.3)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.19.4-\u003edatasets==2.16.1) (4.9.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets==2.16.1) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets==2.16.1) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets==2.16.1) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19.0-\u003edatasets==2.16.1) (2024.2.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets==2.16.1) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003edatasets==2.16.1) (2023.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas-\u003edatasets==2.16.1) (1.16.0)\n"]}],"source":["%%sh\n","\n","pip install bitsandbytes\u003e=0.39.0\n","pip install accelerate==0.26.1\n","# pip install transformers==4.36.1\n","pip install datasets==2.16.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22519,"status":"ok","timestamp":1708265875497,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"Fqr-I_IbWZOr","outputId":"7ee34625-ef8c-4641-bf3c-62db656885db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/azliu0/transformers.git\n","  Cloning https://github.com/azliu0/transformers.git to /tmp/pip-req-build-e2ahip8u\n","  Resolved https://github.com/azliu0/transformers.git to commit 66d2bcde1b0ebc41a428e3ae864dd0c22883cdee\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (3.13.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.20.3)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (2.31.0)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.15.2)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (0.4.2)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0.dev0) (4.66.2)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.19.3-\u003etransformers==4.37.0.dev0) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.19.3-\u003etransformers==4.37.0.dev0) (4.9.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.37.0.dev0) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.37.0.dev0) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.37.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.37.0.dev0) (2024.2.2)\n"]},{"name":"stderr","output_type":"stream","text":["  Running command git clone --filter=blob:none --quiet https://github.com/azliu0/transformers.git /tmp/pip-req-build-e2ahip8u\n"]}],"source":["%%sh\n","\n","pip install git+https://github.com/azliu0/transformers.git"]},{"cell_type":"markdown","metadata":{"id":"Cg-lFpDaiSsg"},"source":["# phase 0-\u003e1 training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PIuuphF-Ek9l"},"outputs":[],"source":["from accelerate import FullyShardedDataParallelPlugin, Accelerator\n","from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n","\n","fsdp_plugin = FullyShardedDataParallelPlugin(\n","    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n","    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",")\n","\n","accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtczjRYcGQxD"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","import transformers\n","import torch\n","\n","# bnb_config = BitsAndBytesConfig(\n","#     load_in_4bit=True,\n","#     bnb_4bit_quant_type=\"nf4\",\n","#     bnb_4bit_use_double_quant=True,\n","# )\n","\n","base_model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"elapsed":414013,"status":"ok","timestamp":1708267447610,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"wrY-i-BxzPaQ","outputId":"0d86e194-7b92-4188-d741-7cfb05cc02b3"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e1ac2d9be004f9c833e41aa62715fcd","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/19 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model_0_1 = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oj07cqKv2b6t"},"outputs":[],"source":["# device = \"cuda\" # the device to load the model onto\n","\n","# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1708267499132,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"RvS0EUL94SBf","outputId":"85f7f644-5970-4fb3-fbca-f419cc7bf7a9"},"outputs":[{"data":{"text/plain":["MixtralForCausalLM(\n","  (model): MixtralModel(\n","    (embed_tokens): Embedding(32000, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x MixtralDecoderLayer(\n","        (self_attn): MixtralAttention(\n","          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): MixtralRotaryEmbedding()\n","        )\n","        (block_sparse_moe): MixtralSparseMoeBlock(\n","          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n","          (experts): ModuleList(\n","            (0-7): 8 x MixtralBLockSparseTop2MLP(\n","              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","              (act_fn): SiLU()\n","            )\n","          )\n","        )\n","        (input_layernorm): MixtralRMSNorm()\n","        (post_attention_layernorm): MixtralRMSNorm()\n","      )\n","    )\n","    (norm): MixtralRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",")"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["model_0_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLmXxag7-jwJ"},"outputs":[],"source":["from datasets import load_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHX4J15H_yTu"},"outputs":[],"source":["import os\n","\n","train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/treehacks/training.jsonl', split='train')\n","eval_dataset = load_dataset('json', data_files='/content/drive/MyDrive/treehacks/validation.jsonl', split='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ollENIrdAPYq"},"outputs":[],"source":["from accelerate import FullyShardedDataParallelPlugin, Accelerator\n","from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n","\n","fsdp_plugin = FullyShardedDataParallelPlugin(\n","    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n","    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",")\n","\n","accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xilEtd61HroI"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    padding_side=\"left\",\n","    add_eos_token=True,\n","    add_bos_token=True,\n",")\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGfdL2-1e0eS"},"outputs":[],"source":["def generate_code_given_nlq(nlq):\n","    messages = [\n","      {\"role\": \"user\", \"content\": f\"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, your response should be `ls`. Please only respond with the command itself. Here is my query: \\\"{nlq}\\\"\"},\n","    ]\n","\n","\n","    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","    model_inputs = encodeds\n","    generated_ids = model_0_1.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","    decoded = tokenizer.batch_decode(generated_ids)\n","    return decoded[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oivATj6QILio"},"outputs":[],"source":["nlq = \"delete the file named `hello.txt`\"\n","print(generate_code_given_nlq(nlq))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CBFhzjq_fv8A"},"outputs":[],"source":["%%sh\n","\n","pip install peft==0.6.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6iCik6_H-wR"},"outputs":[],"source":["from peft import prepare_model_for_kbit_training\n","\n","model_0_1.gradient_checkpointing_enable()\n","model_0_1 = prepare_model_for_kbit_training(model_0_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rJbUW96tuPY"},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PwYzABNtx5l"},"outputs":[],"source":["from peft import LoraConfig, get_peft_model\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","        \"lm_head\",\n","    ],\n","    bias=\"none\",\n","    lora_dropout=0.05,  # Conventional\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model_0_1 = get_peft_model(model_0_1, config)\n","# model = get_peft_model(model, peft_config=config, adapter_name=\"adapter_1\")\n","# model.add_adapter(lora_config=config, adapter_name=\"adapter_1\")\n","print_trainable_parameters(model_0_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2_cu0yT45DO"},"outputs":[],"source":["print(model_0_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgUrkJBcukv4"},"outputs":[],"source":["model_0_1 = accelerator.prepare_model(model_0_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TX2OcKI1uwx3"},"outputs":[],"source":["print(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-Z29TtKuuMG"},"outputs":[],"source":["def generate_and_tokenize_prompt(prompt):\n","      messages = [\n","        {\"role\": \"user\", \"content\": prompt['input']},\n","        {\"role\": \"assistant\", \"content\": prompt['output']},\n","      ]\n","      # encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","      tokens = tokenizer.apply_chat_template(messages, tokenize=True)\n","      return { 'input_ids': tokens, 'attention_mask': [1 for _ in range(len(tokens))] }\n","\n","tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n","tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6xDtWu_kulF2"},"outputs":[],"source":["import transformers\n","from datetime import datetime\n","\n","project = \"mistral-finetune\"\n","base_model_name = \"mistral2\"\n","run_name = base_model_name + \"-\" + project\n","output_dir = \"./\" + run_name\n","\n","# from peft import PeftModel\n","# print(model.config._use_perft)\n","# print(model)\n","\n","# import transformers.trainer\n","\n","# print(dir(transformers.trainer))\n","# print(isinstance(model, PeftModel))\n","# from peft.utils import is_peft_available\n","# print(is_peft_available())\n","\n","trainer = transformers.Trainer(\n","    model=model_0_1.to(\"cuda\"),\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    args=transformers.TrainingArguments(\n","        output_dir=output_dir,\n","        warmup_steps=1,\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        gradient_checkpointing=True,\n","        max_steps=500,\n","        learning_rate=2.5e-5, # Want a small lr for finetuning\n","        bf16=True,\n","        optim=\"paged_adamw_8bit\",\n","        logging_steps=25,              # When to start reporting loss\n","        logging_dir=\"./logs\",        # Directory for storing logs\n","        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n","        save_steps=25,                # Save checkpoints every 50 steps\n","        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n","        # eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n","        do_eval=True,                # Perform evaluation at the end of training\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","\n","model_0_1.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"ezVMNBOeiFoR"},"source":["# phase 1-2 training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGRjtW1_ROSk"},"outputs":[],"source":["%%sh\n","\n","pip install -U transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"elapsed":414423,"status":"ok","timestamp":1708260630869,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"HWcB0OaWibWs","outputId":"e16e9b43-bbf8-4417-c35f-e10e8f666527"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"559bf158ac094f23930734884fc77360","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/19 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","base_model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,  # Mistral, same as before\n","    quantization_config=bnb_config,  # Same quantization config as before\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6RGe2xJiwS0"},"outputs":[],"source":["from peft import PeftModel\n","\n","# take the best model from the previous checkpoint\n","run_name = \"mistral2-mistral-finetune\"\n","ft_model = PeftModel.from_pretrained(base_model, f\"{run_name}/checkpoint-500\").to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8lVOnzV-i3aU"},"outputs":[],"source":["# this is the model we will train to transition between phases 1 and 2\n","model_phase_1_2 = ft_model.base_model.model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1708260676853,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"zvsZgeE1ibWu","outputId":"a8e871be-336a-4d28-c823-b0ae13c577d4"},"outputs":[{"data":{"text/plain":["MixtralForCausalLM(\n","  (model): MixtralModel(\n","    (embed_tokens): Embedding(32000, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x MixtralDecoderLayer(\n","        (self_attn): MixtralAttention(\n","          (q_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          )\n","          (k_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          )\n","          (v_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          )\n","          (o_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          )\n","          (rotary_emb): MixtralRotaryEmbedding()\n","        )\n","        (block_sparse_moe): MixtralSparseMoeBlock(\n","          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n","          (experts): ModuleList(\n","            (0-7): 8 x MixtralBLockSparseTop2MLP(\n","              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","              (act_fn): SiLU()\n","            )\n","          )\n","        )\n","        (input_layernorm): MixtralRMSNorm()\n","        (post_attention_layernorm): MixtralRMSNorm()\n","      )\n","    )\n","    (norm): MixtralRMSNorm()\n","  )\n","  (lm_head): Linear(\n","    in_features=4096, out_features=32000, bias=False\n","    (lora_dropout): ModuleDict(\n","      (default): Dropout(p=0.05, inplace=False)\n","    )\n","    (lora_A): ModuleDict(\n","      (default): Linear(in_features=4096, out_features=32, bias=False)\n","    )\n","    (lora_B): ModuleDict(\n","      (default): Linear(in_features=32, out_features=32000, bias=False)\n","    )\n","    (lora_embedding_A): ParameterDict()\n","    (lora_embedding_B): ParameterDict()\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model_phase_1_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hoW-gFKAibWu"},"outputs":[],"source":["from datasets import load_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49},"executionInfo":{"elapsed":5222,"status":"ok","timestamp":1708260685228,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"oJILPsd0ibWu","outputId":"4918f98a-8e8c-46f5-ddc8-02cd3ea9c27b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af9a755982d34cbeb77556fd83a086d2","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","\n","# now we use the larger, combined dataset for training\n","train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/treehacks/combinedtraining.jsonl', split='train')\n","eval_dataset = load_dataset('json', data_files='/content/drive/MyDrive/treehacks/validation.jsonl', split='train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-HlxTYTibWu"},"outputs":[],"source":["from accelerate import FullyShardedDataParallelPlugin, Accelerator\n","from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n","\n","fsdp_plugin = FullyShardedDataParallelPlugin(\n","    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n","    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",")\n","\n","accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0eHeWayibWu"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n","    padding_side=\"left\",\n","    add_eos_token=True,\n","    add_bos_token=True,\n",")\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2rAXMRGibWu"},"outputs":[],"source":["def generate_code_given_nlq_1_2(nlq):\n","    messages = [\n","      {\"role\": \"user\", \"content\": f\"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, your response should be `ls`. Please only respond with the command itself. Here is my query: \\\"{nlq}\\\"\"},\n","    ]\n","\n","    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","    model_inputs = encodeds\n","\n","    generated_ids = model_phase_1_2.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","    decoded = tokenizer.batch_decode(generated_ids)\n","    return decoded[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTqqdDt1ibWu"},"outputs":[],"source":["# nlq = \"create a cron job that runs the script /home/scrape.sh every 24 hours starting from 8:00pm on Sunday, February 18th, 2024\"\n","# print(generate_code_given_nlq_1_2(nlq))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0eI4LEmZibWv"},"outputs":[],"source":["from peft import prepare_model_for_kbit_training\n","\n","model_phase_1_2.gradient_checkpointing_enable()\n","model_phase_1_2 = prepare_model_for_kbit_training(model_phase_1_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-vrtPzCibWv"},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":911,"status":"ok","timestamp":1708260732708,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"7mSzGWb7ibWv","outputId":"da747f70-10f3-43f7-cf6c-0b6373ccda6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 28418048 || all params: 23511019520 || trainable%: 0.12087118542786188\n"]}],"source":["from peft import LoraConfig, get_peft_model\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","        \"lm_head\",\n","    ],\n","    bias=\"none\",\n","    lora_dropout=0.05,  # Conventional\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model_phase_1_2 = get_peft_model(model_phase_1_2, config)\n","print_trainable_parameters(model_phase_1_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1708260735629,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"yEXgvzYPibWv","outputId":"db452e69-b4f7-456a-87fd-d70b02f1a0ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): MixtralForCausalLM(\n","      (model): MixtralModel(\n","        (embed_tokens): Embedding(32000, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x MixtralDecoderLayer(\n","            (self_attn): MixtralAttention(\n","              (q_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","              )\n","              (k_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","              )\n","              (v_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","              )\n","              (o_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","              )\n","              (rotary_emb): MixtralRotaryEmbedding()\n","            )\n","            (block_sparse_moe): MixtralSparseMoeBlock(\n","              (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n","              (experts): ModuleList(\n","                (0-7): 8 x MixtralBLockSparseTop2MLP(\n","                  (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","                  (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","                  (act_fn): SiLU()\n","                )\n","              )\n","            )\n","            (input_layernorm): MixtralRMSNorm()\n","            (post_attention_layernorm): MixtralRMSNorm()\n","          )\n","        )\n","        (norm): MixtralRMSNorm()\n","      )\n","      (lm_head): Linear(\n","        in_features=4096, out_features=32000, bias=False\n","        (lora_dropout): ModuleDict(\n","          (default): Dropout(p=0.05, inplace=False)\n","        )\n","        (lora_A): ModuleDict(\n","          (default): Linear(in_features=4096, out_features=32, bias=False)\n","        )\n","        (lora_B): ModuleDict(\n","          (default): Linear(in_features=32, out_features=32000, bias=False)\n","        )\n","        (lora_embedding_A): ParameterDict()\n","        (lora_embedding_B): ParameterDict()\n","      )\n","    )\n","  )\n",")\n"]}],"source":["print(model_phase_1_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGlWAuu7ibWv"},"outputs":[],"source":["model_phase_1_2 = accelerator.prepare_model(model_phase_1_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1708260739740,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"5KLIlayGibWv","outputId":"4a2fc70d-3ecc-48cc-ad9d-abcbc5bde9ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['input', 'output'],\n","    num_rows: 19276\n","})\n"]}],"source":["print(train_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"elapsed":13686,"status":"ok","timestamp":1708260755092,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"_NnHeo5BibWv","outputId":"5d36b290-d879-4c46-f9d2-41013ef04e51"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a7ee916a7cc4c99a48c74a1b3033882","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/19276 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6d2a6cbd6874c7eb5f5d6c37053952b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00\u003c?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def generate_and_tokenize_prompt(prompt):\n","      messages = [\n","        {\"role\": \"user\", \"content\": f\"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, your response should be `ls`. Please only respond with the command itself. Here is my query: \\\"{prompt['input']}\\\"\"},\n","        {\"role\": \"assistant\", \"content\": prompt['output']},\n","      ]\n","      # encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","      tokens = tokenizer.apply_chat_template(messages, tokenize=True)\n","      return { 'input_ids': tokens, 'attention_mask': [1 for _ in range(len(tokens))] }\n","\n","tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n","tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2983757,"status":"error","timestamp":1708265292364,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"WVTuZa9-ibWv","outputId":"fc22aebf-7654-4fdd-ddd3-511374a37c8f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    \u003cdiv\u003e\n","      \n","      \u003cprogress value='346' max='500' style='width:300px; height:20px; vertical-align: middle;'\u003e\u003c/progress\u003e\n","      [346/500 49:36 \u003c 22:12, 0.12 it/s, Epoch 0.04/1]\n","    \u003c/div\u003e\n","    \u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n"," \u003ctr style=\"text-align: left;\"\u003e\n","      \u003cth\u003eStep\u003c/th\u003e\n","      \u003cth\u003eTraining Loss\u003c/th\u003e\n","      \u003cth\u003eValidation Loss\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e25\u003c/td\u003e\n","      \u003ctd\u003e2.857500\u003c/td\u003e\n","      \u003ctd\u003e1.846487\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e50\u003c/td\u003e\n","      \u003ctd\u003e1.076200\u003c/td\u003e\n","      \u003ctd\u003e1.102981\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e75\u003c/td\u003e\n","      \u003ctd\u003e0.760000\u003c/td\u003e\n","      \u003ctd\u003e0.807342\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e100\u003c/td\u003e\n","      \u003ctd\u003e0.623100\u003c/td\u003e\n","      \u003ctd\u003e4.800373\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e125\u003c/td\u003e\n","      \u003ctd\u003e0.871900\u003c/td\u003e\n","      \u003ctd\u003e0.694432\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e150\u003c/td\u003e\n","      \u003ctd\u003e0.514400\u003c/td\u003e\n","      \u003ctd\u003e0.643339\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e175\u003c/td\u003e\n","      \u003ctd\u003e0.560900\u003c/td\u003e\n","      \u003ctd\u003e0.641982\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e200\u003c/td\u003e\n","      \u003ctd\u003e0.488400\u003c/td\u003e\n","      \u003ctd\u003e0.624331\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e225\u003c/td\u003e\n","      \u003ctd\u003e0.435600\u003c/td\u003e\n","      \u003ctd\u003e0.637454\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e250\u003c/td\u003e\n","      \u003ctd\u003e0.579700\u003c/td\u003e\n","      \u003ctd\u003e0.582857\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e275\u003c/td\u003e\n","      \u003ctd\u003e0.579100\u003c/td\u003e\n","      \u003ctd\u003e0.765172\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e300\u003c/td\u003e\n","      \u003ctd\u003e0.743100\u003c/td\u003e\n","      \u003ctd\u003e0.798714\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003ctd\u003e325\u003c/td\u003e\n","      \u003ctd\u003e0.605900\u003c/td\u003e\n","      \u003ctd\u003e0.750567\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\u003cp\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-38-451149d795fb\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 48\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel_phase_1_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# silence the warnings. Please re-enable for inference!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 48\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1539\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1540\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1869\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2759\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2761\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2763\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1964\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--\u003e 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import transformers\n","from datetime import datetime\n","\n","project = \"phase-1-2-mistral-finetune\"\n","base_model_name = \"mistral2\"\n","run_name = base_model_name + \"-\" + project\n","output_dir = \"./\" + run_name\n","\n","# from peft import PeftModel\n","# print(model.config._use_perft)\n","# print(model)\n","\n","# import transformers.trainer\n","\n","# print(dir(transformers.trainer))\n","# print(isinstance(model, PeftModel))\n","# from peft.utils import is_peft_available\n","# print(is_peft_available())\n","\n","model_phase_1_2.half()\n","\n","trainer = transformers.Trainer(\n","    model=model_phase_1_2.to(\"cuda\"),\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    args=transformers.TrainingArguments(\n","        output_dir=output_dir,\n","        warmup_steps=1,\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        gradient_checkpointing=True,\n","        max_steps=500,\n","        learning_rate=2.5e-5, # Want a small lr for finetuning\n","        bf16=True,\n","        optim=\"paged_adamw_8bit\",\n","        logging_steps=25,              # When to start reporting loss\n","        logging_dir=\"./logs\",        # Directory for storing logs\n","        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n","        save_steps=25,                # Save checkpoints every 50 steps\n","        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n","        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n","        do_eval=True,                # Perform evaluation at the end of training\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","\n","model_phase_1_2.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgo-2u1Bi-PG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hWzrO9GCbBMb"},"source":["# model evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"elapsed":66121,"status":"ok","timestamp":1708266014501,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"KpYnHyiMbCY1","outputId":"90171dcb-6a1c-4dbc-c6e7-4a6e97133b3f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"569da79c0a344aa1b866ba90b9bc563c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/571 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b189b95ac0de450a8b0010be84b5aa15","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24e85d6636e54e6c954ee57c49f30734","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"866326264ef846a291308f11d322d02d","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e851384654242e3aa55c61224fc0bef","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"269dd24c5e2f4cf5a6d95b0f35c1035b","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5618d28d008409d89e9a953d372b548","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/116 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","base_model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,  # Mistral, same as before\n","    quantization_config=bnb_config,  # Same quantization config as before\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")\n","\n","eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QG6v7EKMslre"},"outputs":[],"source":["run_name_0_1 = \"mistral2-mistral-finetune\"\n","run_name_1_2 = \"mistral2-phase-1-2-mistral-finetune\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2055,"status":"ok","timestamp":1708270098432,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"2yQ9ptMXbSTX","outputId":"b1edbb0f-0355-4ad2-d8a0-b3c0a118bbf2"},"outputs":[{"data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): MistralForCausalLM(\n","      (model): MistralModel(\n","        (embed_tokens): Embedding(32000, 4096)\n","        (layers): ModuleList(\n","          (0-31): 32 x MistralDecoderLayer(\n","            (self_attn): MistralAttention(\n","              (q_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","              )\n","              (k_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","              )\n","              (v_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","              )\n","              (o_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","              )\n","              (rotary_emb): MistralRotaryEmbedding()\n","            )\n","            (mlp): MistralMLP(\n","              (gate_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","              )\n","              (up_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=4096, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=14336, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","              )\n","              (down_proj): Linear4bit(\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=14336, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=4096, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): MistralRMSNorm()\n","            (post_attention_layernorm): MistralRMSNorm()\n","          )\n","        )\n","        (norm): MistralRMSNorm()\n","      )\n","      (lm_head): Linear(\n","        in_features=4096, out_features=32000, bias=False\n","        (lora_dropout): ModuleDict(\n","          (default): Dropout(p=0.05, inplace=False)\n","        )\n","        (lora_A): ModuleDict(\n","          (default): Linear(in_features=4096, out_features=32, bias=False)\n","        )\n","        (lora_B): ModuleDict(\n","          (default): Linear(in_features=32, out_features=32000, bias=False)\n","        )\n","        (lora_embedding_A): ParameterDict()\n","        (lora_embedding_B): ParameterDict()\n","      )\n","    )\n","  )\n",")"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["from peft import PeftModel\n","\n","ft_model_0_1 = PeftModel.from_pretrained(base_model, f\"{run_name_0_1}/checkpoint-500\").to(\"cuda\")\n","# ft_model_1_2 = PeftModel.from_pretrained(base_model, f\"{run_name_1_2}/checkpoint-300\").to(\"cuda\")\n","ft_model_0_1.eval()\n","# ft_model_1_2.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"osWg_Ub0j3Zg"},"outputs":[],"source":["# model_0 = AutoModelForCausalLM.from_pretrained(\n","#     base_model_id,\n","#     quantization_config=bnb_config,\n","#     device_map=\"auto\",\n","#     trust_remote_code=True,\n","# )\n","# model_0_1 = ft_model_0_1.base_model.model\n","model_1_2 = ft_model_1_2.base_model.model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"elapsed":2,"status":"error","timestamp":1708266078377,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"oRat3vkKww2k","outputId":"c174e2bf-e022-4d7b-c1ab-eabfc88bc530"},"outputs":[{"ename":"NameError","evalue":"name 'model_0' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-18-ccc8daca5ca5\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmodel_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_0' is not defined"]}],"source":["model_0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"elapsed":5,"status":"error","timestamp":1708266078795,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"5XgDnX57kDMN","outputId":"30c9bb60-738d-419e-9f57-4e942e24e7af"},"outputs":[{"ename":"NameError","evalue":"name 'model_0_1' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-19-a0144a56a6a0\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmodel_0_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_0_1' is not defined"]}],"source":["model_0_1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1708266079225,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"Le7ppgsluciL","outputId":"f6b2c74e-ddbc-41c4-c723-b87a27b70a6a"},"outputs":[{"data":{"text/plain":["MistralForCausalLM(\n","  (model): MistralModel(\n","    (embed_tokens): Embedding(32000, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x MistralDecoderLayer(\n","        (self_attn): MistralAttention(\n","          (q_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          )\n","          (k_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          )\n","          (v_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n","          )\n","          (o_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n","          )\n","          (rotary_emb): MistralRotaryEmbedding()\n","        )\n","        (mlp): MistralMLP(\n","          (gate_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=14336, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          )\n","          (up_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=14336, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n","          )\n","          (down_proj): Linear4bit(\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=14336, out_features=32, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=32, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n","          )\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): MistralRMSNorm()\n","        (post_attention_layernorm): MistralRMSNorm()\n","      )\n","    )\n","    (norm): MistralRMSNorm()\n","  )\n","  (lm_head): Linear(\n","    in_features=4096, out_features=32000, bias=False\n","    (lora_dropout): ModuleDict(\n","      (default): Dropout(p=0.05, inplace=False)\n","    )\n","    (lora_A): ModuleDict(\n","      (default): Linear(in_features=4096, out_features=32, bias=False)\n","    )\n","    (lora_B): ModuleDict(\n","      (default): Linear(in_features=32, out_features=32000, bias=False)\n","    )\n","    (lora_embedding_A): ParameterDict()\n","    (lora_embedding_B): ParameterDict()\n","  )\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model_1_2\n","# model_1_2 = model_phase_1_2.base_model.model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzHMpXoSj1bo"},"outputs":[],"source":["def generate_code_given_nlq_ft(model, nlq):\n","    messages = [\n","      {\"role\": \"user\", \"content\": f\"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, your response should be `ls`. Please only respond with the command itself. Here is my query: \\\"{nlq}\\\"\"},\n","    ]\n","\n","    encodeds = eval_tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","    model_inputs = encodeds\n","    generated_ids = model.generate(model_inputs, max_new_tokens=100, do_sample=True)\n","    decoded = eval_tokenizer.batch_decode(generated_ids)\n","    return decoded[0]\n","\n","def generate_many_code_given_nlq_ft(model, nlq):\n","    messages = [\n","      {\"role\": \"user\", \"content\": f\"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, your response should be `ls`. Please only respond with the command itself. Here is my query: \\\"{nlq}\\\"\"},\n","    ]\n","\n","    encodeds = eval_tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n","    model_inputs = encodeds\n","    generated_ids = model.generate(model_inputs, max_new_tokens=100, num_return_sequences=3, num_beams=10, do_sample=True, output_scores=True)\n","    decoded = eval_tokenizer.batch_decode(generated_ids)\n","    return str(decoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5237,"status":"ok","timestamp":1708265521850,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"mHCpw2tTuztb","outputId":"7d127464-f8ea-43a1-cfe3-e199c80f05f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai==1.12.0 in /usr/local/lib/python3.10/dist-packages (1.12.0)\n","Requirement already satisfied: anyio\u003c5,\u003e=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0) (3.7.1)\n","Requirement already satisfied: distro\u003c2,\u003e=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.12.0) (1.7.0)\n","Requirement already satisfied: httpx\u003c1,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0) (0.26.0)\n","Requirement already satisfied: pydantic\u003c3,\u003e=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0) (2.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0) (1.3.0)\n","Requirement already satisfied: tqdm\u003e4 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0) (4.66.2)\n","Requirement already satisfied: typing-extensions\u003c5,\u003e=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.12.0) (4.9.0)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.5.0-\u003eopenai==1.12.0) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio\u003c5,\u003e=3.5.0-\u003eopenai==1.12.0) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003eopenai==1.12.0) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003eopenai==1.12.0) (1.0.3)\n","Requirement already satisfied: h11\u003c0.15,\u003e=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*-\u003ehttpx\u003c1,\u003e=0.23.0-\u003eopenai==1.12.0) (0.14.0)\n","Requirement already satisfied: annotated-types\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003c3,\u003e=1.9.0-\u003eopenai==1.12.0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003c3,\u003e=1.9.0-\u003eopenai==1.12.0) (2.16.2)\n"]}],"source":["%%sh\n","\n","pip3 install openai==1.12.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":6,"status":"error","timestamp":1708265521850,"user":{"displayName":"Andrew Liu","userId":"10541625934477981887"},"user_tz":480},"id":"5PGRZShz8lVC","outputId":"20aac553-3ff1-42a1-faf8-4220bc133a20"},"outputs":[{"ename":"NameError","evalue":"name 'model_0_1' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-50-0dec20a344a6\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mmodel_0_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_0_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_0_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_0_1' is not defined"]}],"source":["model_0_1.eval()\n","model_0_1 = model_0_1.base_model.model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_E3v_5yH8sQ3"},"outputs":[],"source":["model_0_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKPo3mcqu4f3"},"outputs":[],"source":["from openai import OpenAI\n","\n","client = OpenAI(api_key=\"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\")\n","\n","import json\n","\n","def generate_code_given_nlq_openai(nlq):\n","  response = client.chat.completions.create(\n","      model = \"gpt-3.5-turbo\",\n","      messages=[\n","          {\"role\": \"system\", \"content\": \"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, you should respond with `ls`\"},\n","          {\"role\": \"user\", \"content\": nlq}\n","      ]\n","  )\n","  return response.choices[0].message.content\n","\n","def generate_openai_prompt(prompt):\n","  print(\"openai prompt\", prompt)\n","  json_prompt = json.loads(prompt)\n","  response = client.chat.completions.create(model=json_prompt[\"model\"], messages=json_prompt[\"messages\"])\n","  return response.choices[0].message.content\n","\n","def generate_many_code_given_nlq_openai(nlq):\n","  response = client.chat.completions.create(\n","      model = \"gpt-3.5-turbo\",\n","      messages=[\n","          {\"role\": \"system\", \"content\": \"You are a terminal assistant. Your should respond to my query with a terminal command in MacOS that will solve the problem that I am having trouble with, and nothing else. I should be able to copy-paste your answer directly into my terminal and run it. For example, if I ask you how to list the contents of the current directory, you should respond with `ls`\"},\n","          {\"role\": \"user\", \"content\": nlq}\n","      ]\n","  )\n","  return str(response.choices[0])"]},{"cell_type":"markdown","metadata":{"id":"itgSpswLg2jw"},"source":["# server stuff"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HufFldNagxhT"},"outputs":[],"source":["%%sh\n","\n","pip -q install pyngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xd5oZHYeg6uK"},"outputs":[],"source":["%%sh\n","\n","pip -q install public_ip\n","pip -q install uvicorn nest_asyncio\n","pip install -q fastapi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0xwLluWg-ke"},"outputs":[],"source":["from fastapi import FastAPI\n","import nest_asyncio\n","import uvicorn\n","import public_ip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-7EtmL8ypWAL"},"outputs":[],"source":["from pydantic import BaseModel\n","\n","class QueryParams(BaseModel):\n","    query: str\n","    model: str\n","\n","class OpenAIReq(BaseModel):\n","    model: str\n","    messages: list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAhaVFmDg_7N"},"outputs":[],"source":["app = FastAPI()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1_m_PPlmiRw"},"outputs":[],"source":["@app.get('/')\n","async def root():\n","    return {\"message\":\"root\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4xkkfu0ECc_"},"outputs":[],"source":["@app.post('/zig')\n","async def zig(openai_req: OpenAIReq):\n","    messages = openai_req.messages\n","    print(\"messages\", type(messages), messages)\n","    response = generate_code_given_nlq_ft(model_0_1,messages[0][\"content\"])\n","    index = response.index(\"[/INST]\")\n","    if (index == -1):\n","        return {\"data\":response[:-4]}\n","    else:\n","        return {\"data\":response[index+8:-4]}\n","    return {\"data\":generate_code_given_nlq_ft(model_0_1,messages[0][\"content\"])}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"De6WAmHBifcC"},"outputs":[],"source":["@app.post('/generate_code')\n","async def generate_code(query_params : QueryParams):\n","    query = query_params.query\n","    model = query_params.model\n","    if model == \"openai\":\n","        return {\"message\":generate_code_given_nlq_openai(query)}\n","    elif model == \"0\":\n","        return {\"message\":generate_code_given_nlq_ft(model_0, query)}\n","    elif model == \"1\":\n","        return {\"message\":generate_code_given_nlq_ft(model_0_1, query)}\n","    elif model == \"2\":\n","        return {\"message\":generate_code_given_nlq_ft(model_1_2, query)}\n","    return {\"message\":\"invalid query!\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SXpRB6nevnIY"},"outputs":[],"source":["@app.post('/generate_many_code')\n","async def generate_many_code(query_params: QueryParams):\n","    query = query_params.query\n","    model = query_params.model\n","    if model == \"openai\":\n","        return {\"message\":generate_many_code_given_nlq_openai(query)}\n","    elif model == \"0\":\n","        return {\"message\":generate_many_code_given_nlq_ft(model_0, query)}\n","    elif model == \"1\":\n","        return {\"message\":generate_many_code_given_nlq_ft(model_0_1, query)}\n","    if model == \"2\":\n","        return {\"message\":generate_many_code_given_nlq_ft(model_1_2, query)}\n","    return {\"message\":\"invalid query!\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Pgcx6We9H_h"},"outputs":[],"source":["# @app.post('/openai')\n","# async def call_openai(openai_req: OpenAIReq):\n","#     return {\"data\":generate_openai_prompt(openai_req.json())}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiZHQQoRhkRP"},"outputs":[],"source":["%%sh\n","\n","ngrok config add-authtoken 2YMYFw54vYbgxqSrZUGiQzvo7qN_58yNdtvTWPZ1hGjHPwVhJ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMI6Zj5o_E0a"},"outputs":[],"source":["%%sh\n","\n","pip install sse-starlette"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MID-FwA6_Rlh"},"outputs":[],"source":["import asyncio\n","\n","status_stream_delay = 0.1  # second\n","status_stream_retry_timeout = 30000  # milisecond\n","\n","async def status_event_generator(request, message):\n","    curmsg = message\n","    print(curmsg)\n","    while True:\n","        print(curmsg)\n","        if await request.is_disconnected():\n","            print('Request disconnected')\n","            break\n","\n","        if len(curmsg) == 0:\n","            print('Request completed. Disconnecting now')\n","            yield {\n","                \"event\": \"end\",\n","                \"data\" : ''\n","            }\n","            break\n","\n","        sendData = curmsg[:3] if len(curmsg) \u003e 3 else curmsg\n","        yield {\n","            \"event\": \"update\",\n","            \"data\": ' '.join(sendData)\n","        }\n","\n","        curmsg = curmsg[3:] if len(curmsg) \u003e 3 else []\n","        await asyncio.sleep(status_stream_delay)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XB8zVz0tHW76"},"outputs":[],"source":["from fastapi import FastAPI, Request\n","from starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\n","from starlette.requests import Request\n","from starlette.responses import Response\n","from starlette.types import ASGIApp, Receive, Scope, Send\n","\n","async def __call__(self, scope: Scope, receive: Receive, send: Send) -\u003e None:\n","    print(\"inside of this middleware\")\n","    if scope[\"type\"] != \"http\":\n","        await self.app(scope, receive, send)\n","        return\n","\n","    request = Request(scope, receive=receive)\n","    response = await self.dispatch_func(request, self.call_next)\n","    await response(scope, receive, send)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssrld9O0_F4k"},"outputs":[],"source":["# from sse_starlette.sse import EventSourceResponse\n","# from fastapi import APIRouter, Request\n","\n","# @app.post('/openai')\n","# async def runStatus(\n","#         openai_req: OpenAIReq,\n","#     request: Request,\n","# ):\n","#     message = generate_openai_prompt(openai_req.json())\n","#     print(message, message.split())\n","#     event_generator = status_event_generator(request, message.split())\n","#     return EventSourceResponse(event_generator)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"EiYKghyThUSw"},"outputs":[{"name":"stdout","output_type":"stream","text":["Public URL: https://8c4af8d9178c.ngrok.app\n"]},{"name":"stderr","output_type":"stream","text":["INFO:     Started server process [94488]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:7000 (Press CTRL+C to quit)\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     35.237.4.214:0 - \"GET / HTTP/1.1\" 200 OK\n","INFO:     35.237.4.214:0 - \"GET / HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how do i use ls\\n\\x00'}]\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1665: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["INFO:     171.64.77.46:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '\\x1b[A\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'test\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'hi\\n\\x00'}]\n","INFO:     171.64.77.66:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how do i ls human readable\\n\\x00'}]\n","INFO:     171.64.77.66:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'test\\n\\x00'}]\n","INFO:     171.64.77.65:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls human readable\\n\\x00'}]\n","INFO:     171.64.77.55:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls human readable\\n\\x00'}]\n","INFO:     171.64.77.55:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls human readable\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'cron job for emailing me the sunrise time fetched from an external api every wednesday at 8pm\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '\\x1b[A\\n\\x00'}]\n","INFO:     171.64.77.53:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls human readable\\n\\x00'}]\n","INFO:     171.64.77.63:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'cron job for emailing me sunrise time from external api every wednesday night\\n\\x00'}]\n","INFO:     171.64.77.53:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'change permissions of all files in a folder to be rwx by all\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how much space is my home directory taking up?\\n\\x00'}]\n","INFO:     171.64.77.63:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all files in the current directory that are writable by their owner\\n\\x00'}]\n","INFO:     171.64.77.63:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'recursively set all permissions under ../tools to 777\\n\\x00'}]\n","INFO:     171.64.77.60:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'enable dot glob shell option\\n\\x00'}]\n","INFO:     171.64.77.60:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'what percentage of my zshell history is git commits?\\n\\x00'}]\n","INFO:     171.64.77.60:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'show me top\\n\\x00'}]\n","INFO:     171.64.77.63:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'what percentage of my zshell history is git commits?\\n\\x00'}]\n","INFO:     171.64.77.63:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'what percentage of my zshell history is git commits?\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'what percentage of my zshell history is git commits?\\n\\x00'}]\n","INFO:     171.64.77.50:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'tes\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all files that are newer than january 1 2024 in the current directory\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all files that are newer than january 1 2024 in the current directory\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all .py files that are newer than february 16 2024 in the current directory\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all .py files that are newer than 2023 in the current directory\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all .py files that are owned by albert in the current directory\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how do i do a cron job that calls some external API url (to be specified) every wednesday at 8pm\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how do i start a cron job that makes a post request to some api every wednesday at 6pm\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'hi\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls human readable'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': \"how do i make the output of ls human readable'\\n\\x00\"}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how do i start a cron job that calls an api every wednesday at 8pm\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'show me the contents of this folder\\n\\x00'}]\n","INFO:     68.65.169.186:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the .py files in this folder that are owned by albert\\n\\x00'}]\n","INFO:     68.65.169.186:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls in human readable format\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the .py files in ~/treehacks that are owned by albert\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the *.py files in ~/treehacks that belong to albert\\n\\x00'}]\n","INFO:     68.65.169.183:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all the files in human readable format\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the .py files in ~/treehacks that are owned by albert\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'klsdfjkdlsjfkl\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'hi\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'how do i start a cron job to post some external api every wednesday at 6pm\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all the files in the folder that are human readable\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'show system stats\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'install ffmpeg\\n\\x00'}]\n","INFO:     68.65.169.186:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '\\n\\x00'}]\n","INFO:     68.65.169.180:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all files in a human readable format\\n\\x00'}]\n","INFO:     68.65.169.180:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all python files in my treehacks folder owned by albert\\n\\x00'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'go to my courses directory\\n\\x00'}]\n","INFO:     68.65.169.186:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the python files in this directory\\n\\x00'}]\n","INFO:     68.65.169.186:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all the files in this directory in human readable format\\n\\x00'}]\n","INFO:     68.65.169.180:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the python files in this directory that are owned by albert\\n\\x00'}]\n","INFO:     68.65.169.180:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all the files in this directory in  human readable format\\n\\x00'}]\n","INFO:     68.65.169.180:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'ls\\n\\x00'}]\n","INFO:     68.65.169.184:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the python files in this folder'}]\n","INFO:     68.65.169.182:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all the files in this directory in human readable format\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all the python files in my ~/treehacks directory owned by albert\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'what version of python am i using?\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all files \\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all files in this directory\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'find all python files in the current directory owned by albert\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all files\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'list all files\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'help \\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'give me the time'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'can you code me a program that says hi every 10 seconds'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'can you code me a program that says hi every 10 seconds'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'can you code me a program that says hi every 10 seconds but only 10 times'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'can you code me a program that says hi every 1 seconds but only 10 times'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'write me a program that echos hello 10 times every 1 second\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'write me a program that echos hello 10 times every 1 second and enclose it in backticks\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'execute the zz command\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'i have an installed command called \"zz\" can you write a script to run the command\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'i have an executable at \"/Users/albert/treehacks/zig_out/bin/zyzx\". can you write a script to call this executable\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': '/Users/albert/treehack\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]},{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["messages \u003cclass 'list'\u003e [{'role': 'user', 'content': 'write a self generating scrip[t\\n\\x00'}]\n","INFO:     2607:f6d0:ced:5b4:6c92:26a6:3200:dd21:0 - \"POST /zig HTTP/1.1\" 200 OK\n"]}],"source":["from pyngrok import ngrok\n","ngrok_tunnel = ngrok.connect(7000)\n","print('Public URL:', ngrok_tunnel.public_url)\n","nest_asyncio.apply()\n","uvicorn.run(app, port=7000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HL2Bv11rMAc"},"outputs":[],"source":["%%sh\n","\n","du -sh \"mistral2-mistral-finetune/checkpoint-500\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ax8Wq5WrS--"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMWr1KhKPDgq8p+0XpOyE3Z","gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00d9b2e87345447e82ad53a81e74bef4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_616a294577a54118944dc17c1bb07e66","placeholder":"","style":"IPY_MODEL_5cf7657fc90e4671a84fc0b9e5b60cdf","value":"model-00001-of-00002.safetensors:100%"}},"023c65c1acbc4474a31cb706ea091780":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"049c4210713041ee80d38fe3d635ae03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a7ee916a7cc4c99a48c74a1b3033882":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f738b7db94748508847f52b6e8704b2","IPY_MODEL_69ea7ced74d14336ae2575111ca87a0f","IPY_MODEL_9ab1a0240da64a82be0ba69e64c63b8c"],"layout":"IPY_MODEL_43671ef948644544a3effa47d080c025"}},"0b09cbdd84c747518858ff5b4f93ec7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9c3bfde2eb944fe97e5382d9559e0a4","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8fe955e83744c5c924f2578c76e0329","value":19}},"0b1c683c439a4e69a6ea54a5132db263":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d9add7063be48e49d3ccdb418bfafea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e78017dfb8945a7830ccdf0e0142f75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0efcbae2db6149efb55b06f84029af6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15692a7029de428fa68d9091300341d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16496fbecb17439395ef87dc9103af5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18ccfb3b50c245168c1620b1e8e7f3b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e54becab3f9f4e5bba0c58bf872607c6","placeholder":"","style":"IPY_MODEL_5375427aa4e6418bb692e5e7144fdbf3","value":"model.safetensors.index.json:100%"}},"199f0230d130405b9305ce412dde644b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3428a637b7c542b597fc0753457ec551","placeholder":"","style":"IPY_MODEL_bc6603d822974fb2b672f2364f74bc2a","value":"model-00002-of-00002.safetensors:100%"}},"219f3b6ece5b4da8a1c03b9bf9b14d9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24e85d6636e54e6c954ee57c49f30734":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de1b6a422b504c479a48854f58e60049","IPY_MODEL_83faf75c1b1b4743a66fac6a7aacb276","IPY_MODEL_9e651b0f8cd54752a1833cc92c046a2f"],"layout":"IPY_MODEL_16496fbecb17439395ef87dc9103af5d"}},"269dd24c5e2f4cf5a6d95b0f35c1035b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b420a29c41094f578213fb1ce6187b8b","IPY_MODEL_42d3ac60b2f14144b9e36049b67a4a55","IPY_MODEL_d2582e2f879540c681251c99e2e6bdf7"],"layout":"IPY_MODEL_89e92852eb3545e785db5fe650a152d0"}},"2cffd9c14fca454aa156b5f5ced6f53d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31b72b0d0d8943b78d44b05f64baa656":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f20e9fc8335d41e6b699d8da2b2b69b7","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4fdefbf4db049e88427325b86e2d000","value":19}},"330e052f69264f8f8e43160b36156439":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3428a637b7c542b597fc0753457ec551":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"356afd9f9e5044bea9fff79776c2f4c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"35cde7eeb9a14cec8bd7a02a56e4b381":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cdd16745cd5492394ec0c72d9316e93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e6671a18ed64de7ad7bef192a2dc988":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e100ae6bb77648728cd12bdca5065ff2","placeholder":"","style":"IPY_MODEL_4f49140a117942a2a1a9b7becc2f3b01","value":"4.54G/4.54G[00:16\u0026lt;00:00,397MB/s]"}},"3f738b7db94748508847f52b6e8704b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3f715e992a74c60bfdf59c6736eed28","placeholder":"","style":"IPY_MODEL_a93cbfc1561f4958b7e2f89798fba85a","value":"Map:100%"}},"42d3ac60b2f14144b9e36049b67a4a55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78476da3691f4b6fbdc3dc13a590e6ad","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3c6efde1c7d4ab09e96fb4c34b4550c","value":2}},"4355dd94c8ea455cb890aa1d576febe8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43671ef948644544a3effa47d080c025":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b57827509a47b8a428b2203d37e62e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b3ee047b4ed45a5b7e1fc447a37c09f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d4448a534c04beda33ef3e1c26a14e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_330e052f69264f8f8e43160b36156439","max":9942981696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b76f284e91824805994225097428202c","value":9942981696}},"4e1ac2d9be004f9c833e41aa62715fcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_776a8b152a994efe915b3d4342a8c356","IPY_MODEL_0b09cbdd84c747518858ff5b4f93ec7e","IPY_MODEL_907492b081fd47969c66f529c249e81f"],"layout":"IPY_MODEL_829e6086099d48138d717851b4fbefc9"}},"4e7c5c0c288c40149ad49cacb453bcff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f49140a117942a2a1a9b7becc2f3b01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52587a5b180b4282acb7a710736d205c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5375427aa4e6418bb692e5e7144fdbf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"559bf158ac094f23930734884fc77360":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1d8e00c8d5d4239a5c05322408f66f7","IPY_MODEL_31b72b0d0d8943b78d44b05f64baa656","IPY_MODEL_e5c2aef402dd4d2da4193abd6855bc93"],"layout":"IPY_MODEL_cc4c9dfb227e4d62ae6110d838ee1ccf"}},"569da79c0a344aa1b866ba90b9bc563c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a66e0d8330364f14b5b1d1db353695c5","IPY_MODEL_abbdfa480a0949eb97f49c4a6bac5a50","IPY_MODEL_f6f727d817494d7a8c72188f3adcb835"],"layout":"IPY_MODEL_e31023a0aa0d47d39e7e72288b673462"}},"58769cfa126b4395ba3a6bafacd6ba1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"588710fcd133412db78b5ca049349927":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b88e2bd28d041b38458cf3e4e9e9593":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cf7657fc90e4671a84fc0b9e5b60cdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d063b09602b4887ab228f734c1ebe0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0580756585744718a0753c01c4d7ae5","placeholder":"","style":"IPY_MODEL_049c4210713041ee80d38fe3d635ae03","value":"25.1k/25.1k[00:00\u0026lt;00:00,1.83MB/s]"}},"616a294577a54118944dc17c1bb07e66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e9f5f30b1d41e98c04acf4dde7d89c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68132ccb3d6b420790e2fb77a63f886a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c73b01ff3a6244a5960cefb270bc460e","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8024b060810f47e48c03bcf6aee1e214","value":116}},"69c4007d28904455aef88083217ffe8d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69ea7ced74d14336ae2575111ca87a0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf3df7d3acc84b7e83f8665ace029158","max":19276,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ce0cb294c5a45c0ab0f80dcdcacba5e","value":19276}},"6bdd67a51a5740818d4c93797c6f48fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"776a8b152a994efe915b3d4342a8c356":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c14f78edbae5411d83d5f9bb3c91cefd","placeholder":"","style":"IPY_MODEL_4b3ee047b4ed45a5b7e1fc447a37c09f","value":"Loadingcheckpointshards:100%"}},"78476da3691f4b6fbdc3dc13a590e6ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79cc66626e894e50904eec3df7246cff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cec43e7aadec4ea5bfa705de8e4e6191","max":4540516344,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cffd9c14fca454aa156b5f5ced6f53d","value":4540516344}},"7f6543eefc414b6cb093788862d29c06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fc6a32f339147d7a1c0d36758b8f55e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8024b060810f47e48c03bcf6aee1e214":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"829e6086099d48138d717851b4fbefc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83185554d914473484da1580c1b5906d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83c8f7fa89e149219024fb2f8378e4c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83faf75c1b1b4743a66fac6a7aacb276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a78a71681c1c4846a853468b36d3ee35","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e78017dfb8945a7830ccdf0e0142f75","value":2}},"8448a21068f04d528e1409fb92f5a501":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"866326264ef846a291308f11d322d02d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_00d9b2e87345447e82ad53a81e74bef4","IPY_MODEL_4d4448a534c04beda33ef3e1c26a14e0","IPY_MODEL_ca591a1f5b314991966f15a1db7c2df1"],"layout":"IPY_MODEL_af7824c8c925480987b35eee2aba65f0"}},"86ac63b0829c4dac843154575c30d04c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89e92852eb3545e785db5fe650a152d0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ce0cb294c5a45c0ab0f80dcdcacba5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e00c1f7ac3d4fc7aa01b514be27fc8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"907492b081fd47969c66f529c249e81f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52587a5b180b4282acb7a710736d205c","placeholder":"","style":"IPY_MODEL_a0a498477bfe415db9ef5d5eb07b3622","value":"19/19[06:48\u0026lt;00:00,20.12s/it]"}},"9ab1a0240da64a82be0ba69e64c63b8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb5b4593107246848d30a9428be28518","placeholder":"","style":"IPY_MODEL_83185554d914473484da1580c1b5906d","value":"19276/19276[00:12\u0026lt;00:00,1423.33examples/s]"}},"9af2c5d3cf294332af8af398999f79d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e651b0f8cd54752a1833cc92c046a2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d9add7063be48e49d3ccdb418bfafea","placeholder":"","style":"IPY_MODEL_69c4007d28904455aef88083217ffe8d","value":"2/2[00:46\u0026lt;00:00,22.02s/it]"}},"9e851384654242e3aa55c61224fc0bef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_199f0230d130405b9305ce412dde644b","IPY_MODEL_79cc66626e894e50904eec3df7246cff","IPY_MODEL_3e6671a18ed64de7ad7bef192a2dc988"],"layout":"IPY_MODEL_cf0eb0dbc20943a685f4c0cf1ce268d3"}},"a0580756585744718a0753c01c4d7ae5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0a498477bfe415db9ef5d5eb07b3622":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3c6efde1c7d4ab09e96fb4c34b4550c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5618d28d008409d89e9a953d372b548":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5e761f4c05b41558ab1610c2f755a72","IPY_MODEL_68132ccb3d6b420790e2fb77a63f886a","IPY_MODEL_c6ab6b7a37764c6db7d3ab5d499a4d8e"],"layout":"IPY_MODEL_83c8f7fa89e149219024fb2f8378e4c5"}},"a5e761f4c05b41558ab1610c2f755a72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8448a21068f04d528e1409fb92f5a501","placeholder":"","style":"IPY_MODEL_4e7c5c0c288c40149ad49cacb453bcff","value":"generation_config.json:100%"}},"a66e0d8330364f14b5b1d1db353695c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46b57827509a47b8a428b2203d37e62e","placeholder":"","style":"IPY_MODEL_86ac63b0829c4dac843154575c30d04c","value":"config.json:100%"}},"a70b57fcf7ef4cc39c5114476eab2fe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f92824fb6f184b9eb776e5d0df1f80fa","max":25125,"min":0,"orientation":"horizontal","style":"IPY_MODEL_acc2cfc556684c4ab65ef2af99c942e3","value":25125}},"a78a71681c1c4846a853468b36d3ee35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93cbfc1561f4958b7e2f89798fba85a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa39fe2c05b149ffb57171dbaa0e24ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abb8e6824a7d4177b79c22598566de07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abbdfa480a0949eb97f49c4a6bac5a50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b1c683c439a4e69a6ea54a5132db263","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0efcbae2db6149efb55b06f84029af6b","value":571}},"acc2cfc556684c4ab65ef2af99c942e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad2afc3265804de08209c03de68940a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae94e8ce6fad4a47b2c8d8d569cbae67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af7824c8c925480987b35eee2aba65f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af9a755982d34cbeb77556fd83a086d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0b8a22e31c645819e30c457dece97b2","IPY_MODEL_cfb089422b92459089cd9b8af5e59d2a","IPY_MODEL_ec4357f2408b42ad8f8712353e2c7648"],"layout":"IPY_MODEL_7fc6a32f339147d7a1c0d36758b8f55e"}},"b189b95ac0de450a8b0010be84b5aa15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18ccfb3b50c245168c1620b1e8e7f3b6","IPY_MODEL_a70b57fcf7ef4cc39c5114476eab2fe4","IPY_MODEL_5d063b09602b4887ab228f734c1ebe0c"],"layout":"IPY_MODEL_219f3b6ece5b4da8a1c03b9bf9b14d9a"}},"b420a29c41094f578213fb1ce6187b8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64e9f5f30b1d41e98c04acf4dde7d89c","placeholder":"","style":"IPY_MODEL_3cdd16745cd5492394ec0c72d9316e93","value":"Loadingcheckpointshards:100%"}},"b6d2a6cbd6874c7eb5f5d6c37053952b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e258ebc11b164431afcaeae406cbcc4b","IPY_MODEL_e9fdc83a96cb4f3e84c348f2469c38e2","IPY_MODEL_f4a1067c505c487d9dbd199ed6c66d3d"],"layout":"IPY_MODEL_15692a7029de428fa68d9091300341d0"}},"b76f284e91824805994225097428202c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8fe955e83744c5c924f2578c76e0329":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb5b4593107246848d30a9428be28518":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc6603d822974fb2b672f2364f74bc2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be029776c805464984f57ab8cf4089c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bf3df7d3acc84b7e83f8665ace029158":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf6ef9ad06554a3aa12fa1056fc8dbf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c14f78edbae5411d83d5f9bb3c91cefd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d8e00c8d5d4239a5c05322408f66f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee7d2cc3c07e4068a7a141d0b1ba7cfd","placeholder":"","style":"IPY_MODEL_fef8eb9626284a38a6b3b238a91243cb","value":"Loadingcheckpointshards:100%"}},"c6ab6b7a37764c6db7d3ab5d499a4d8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b88e2bd28d041b38458cf3e4e9e9593","placeholder":"","style":"IPY_MODEL_bf6ef9ad06554a3aa12fa1056fc8dbf6","value":"116/116[00:00\u0026lt;00:00,9.71kB/s]"}},"c73b01ff3a6244a5960cefb270bc460e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca591a1f5b314991966f15a1db7c2df1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_023c65c1acbc4474a31cb706ea091780","placeholder":"","style":"IPY_MODEL_7f6543eefc414b6cb093788862d29c06","value":"9.94G/9.94G[00:29\u0026lt;00:00,479MB/s]"}},"cc4c9dfb227e4d62ae6110d838ee1ccf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec43e7aadec4ea5bfa705de8e4e6191":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf0eb0dbc20943a685f4c0cf1ce268d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfb089422b92459089cd9b8af5e59d2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be029776c805464984f57ab8cf4089c4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efe64ccd567748c499698088916b57cc","value":1}},"d178d56cd7c74c77bd3b398efbbbeaf6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2582e2f879540c681251c99e2e6bdf7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58769cfa126b4395ba3a6bafacd6ba1e","placeholder":"","style":"IPY_MODEL_ff626b755ef744a5bafc945e6bcd373b","value":"2/2[00:07\u0026lt;00:00,3.66s/it]"}},"db6410ed18064379af37d76e518e118d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1b6a422b504c479a48854f58e60049":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e91b3434932942a8adf2486828204fd0","placeholder":"","style":"IPY_MODEL_4355dd94c8ea455cb890aa1d576febe8","value":"Downloadingshards:100%"}},"e100ae6bb77648728cd12bdca5065ff2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e258ebc11b164431afcaeae406cbcc4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9af2c5d3cf294332af8af398999f79d3","placeholder":"","style":"IPY_MODEL_356afd9f9e5044bea9fff79776c2f4c4","value":"Map:100%"}},"e31023a0aa0d47d39e7e72288b673462":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3f715e992a74c60bfdf59c6736eed28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e54becab3f9f4e5bba0c58bf872607c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5c2aef402dd4d2da4193abd6855bc93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e00c1f7ac3d4fc7aa01b514be27fc8c","placeholder":"","style":"IPY_MODEL_f83615e93b6943fea4b80103beb701ad","value":"19/19[06:41\u0026lt;00:00,20.00s/it]"}},"e91b3434932942a8adf2486828204fd0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9fdc83a96cb4f3e84c348f2469c38e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_588710fcd133412db78b5ca049349927","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad2afc3265804de08209c03de68940a9","value":1000}},"ec4357f2408b42ad8f8712353e2c7648":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35cde7eeb9a14cec8bd7a02a56e4b381","placeholder":"","style":"IPY_MODEL_f21f03b3731742fbb2150c7f920b9155","value":"19276/0[00:00\u0026lt;00:00,29685.11examples/s]"}},"ee7d2cc3c07e4068a7a141d0b1ba7cfd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efe64ccd567748c499698088916b57cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0b8a22e31c645819e30c457dece97b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abb8e6824a7d4177b79c22598566de07","placeholder":"","style":"IPY_MODEL_aa39fe2c05b149ffb57171dbaa0e24ee","value":"Generatingtrainsplit:"}},"f20e9fc8335d41e6b699d8da2b2b69b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f21f03b3731742fbb2150c7f920b9155":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4a1067c505c487d9dbd199ed6c66d3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db6410ed18064379af37d76e518e118d","placeholder":"","style":"IPY_MODEL_6bdd67a51a5740818d4c93797c6f48fa","value":"1000/1000[00:00\u0026lt;00:00,1629.61examples/s]"}},"f4fdefbf4db049e88427325b86e2d000":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6f727d817494d7a8c72188f3adcb835":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae94e8ce6fad4a47b2c8d8d569cbae67","placeholder":"","style":"IPY_MODEL_d178d56cd7c74c77bd3b398efbbbeaf6","value":"571/571[00:00\u0026lt;00:00,44.0kB/s]"}},"f83615e93b6943fea4b80103beb701ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f92824fb6f184b9eb776e5d0df1f80fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9c3bfde2eb944fe97e5382d9559e0a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fef8eb9626284a38a6b3b238a91243cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff626b755ef744a5bafc945e6bcd373b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}